diff --git a/src/Conversion/ONNXToMhlo/CMakeLists.txt b/src/Conversion/ONNXToMhlo/CMakeLists.txt
index bd7283a9..fa34d0c7 100644
--- a/src/Conversion/ONNXToMhlo/CMakeLists.txt
+++ b/src/Conversion/ONNXToMhlo/CMakeLists.txt
@@ -46,6 +46,7 @@ add_onnx_mlir_library(OMONNXToMhlo
   Tensor/Gather.cpp
   Tensor/Identity.cpp
   Tensor/Reshape.cpp
+  Tensor/Pad.cpp
   Tensor/Shape.cpp
   Tensor/Slice.cpp
   Tensor/Split.cpp
diff --git a/src/Conversion/ONNXToMhlo/ConvertONNXToMhlo.cpp b/src/Conversion/ONNXToMhlo/ConvertONNXToMhlo.cpp
index 98a9f71e..1a3c6cf5 100644
--- a/src/Conversion/ONNXToMhlo/ConvertONNXToMhlo.cpp
+++ b/src/Conversion/ONNXToMhlo/ConvertONNXToMhlo.cpp
@@ -43,6 +43,7 @@ void populateONNXToMhloConversionPattern(
   populateLoweringONNXGatherOpToMhloPattern(patterns, ctx);
   populateLoweringONNXIdentityOpToMhloPattern(patterns, ctx);
   populateLoweringONNXReshapeOpToMhloPattern(patterns, ctx);
+  populateLoweringONNXPadOpToMhloPattern(patterns, ctx);
   populateLoweringONNXShapeOpToMhloPattern(patterns, ctx);
   populateLoweringONNXSliceOpToMhloPattern(patterns, ctx);
   populateLoweringONNXSplitOpToMhloPattern(patterns, ctx);
diff --git a/src/Conversion/ONNXToMhlo/ONNXToMhloCommon.cpp b/src/Conversion/ONNXToMhlo/ONNXToMhloCommon.cpp
index 4e4adfc1..5b39e407 100644
--- a/src/Conversion/ONNXToMhlo/ONNXToMhloCommon.cpp
+++ b/src/Conversion/ONNXToMhlo/ONNXToMhloCommon.cpp
@@ -93,4 +93,17 @@ llvm::SmallVector<Value, 4> getBroadcastedOperands(
   }
   return broadcastedOperands;
 }
+
+ElementsAttr getElementAttributeFromMhloValue(Value value) {
+  auto definingOp = value.getDefiningOp();
+  if (auto constantOp = dyn_cast_or_null<mhlo::ConstantOp>(definingOp)) {
+    return constantOp.getValue().dyn_cast<ElementsAttr>();
+  } else if (auto constantOp =
+                 dyn_cast_or_null<mlir::ONNXConstantOp>(definingOp)) {
+    if (constantOp.getValue().has_value())
+      return constantOp.getValueAttr().dyn_cast<ElementsAttr>();
+  }
+  return nullptr;
+}
+
 } // namespace onnx_mlir
diff --git a/src/Conversion/ONNXToMhlo/ONNXToMhloCommon.hpp b/src/Conversion/ONNXToMhlo/ONNXToMhloCommon.hpp
index ec5a9f2b..abb33e72 100644
--- a/src/Conversion/ONNXToMhlo/ONNXToMhloCommon.hpp
+++ b/src/Conversion/ONNXToMhlo/ONNXToMhloCommon.hpp
@@ -113,6 +113,8 @@ llvm::SmallVector<Value, 4> getBroadcastedOperands(
     llvm::SmallVector<Value, 4> &operands, Type outputType,
     ConversionPatternRewriter &rewriter, Location loc, int64_t outputRank);
 
+mlir::ElementsAttr getElementAttributeFromMhloValue(mlir::Value value);
+
 // `Math` directory methods:
 void populateLoweringONNXClipOpToMhloPattern(
     RewritePatternSet &, MLIRContext *);
@@ -150,6 +152,8 @@ void populateLoweringONNXGatherOpToMhloPattern(
     RewritePatternSet &, MLIRContext *);
 void populateLoweringONNXIdentityOpToMhloPattern(
     RewritePatternSet &, MLIRContext *);
+void populateLoweringONNXPadOpToMhloPattern(
+    RewritePatternSet &, MLIRContext *);
 void populateLoweringONNXReshapeOpToMhloPattern(
     RewritePatternSet &, MLIRContext *);
 void populateLoweringONNXShapeOpToMhloPattern(
diff --git a/src/Conversion/ONNXToMhlo/Tensor/Pad.cpp b/src/Conversion/ONNXToMhlo/Tensor/Pad.cpp
new file mode 100644
index 00000000..20a43626
--- /dev/null
+++ b/src/Conversion/ONNXToMhlo/Tensor/Pad.cpp
@@ -0,0 +1,99 @@
+/*
+ * SPDX-License-Identifier: Apache-2.0
+ */
+
+//===----------- Pad.cpp - Lowering Pad Op ------------===//
+//
+// Copyright 2022
+//
+// =============================================================================
+//
+// This file lowers ONNX Pad Operators to Mhlo dialect.
+//
+//===----------------------------------------------------------------------===//
+
+#include "src/Conversion/ONNXToMhlo/ONNXToMhloCommon.hpp"
+#include "src/Dialect/ONNX/ElementsAttr/DisposableElementsAttr.hpp"
+#include "src/Dialect/ONNX/ONNXOps/ShapeHelper.hpp"
+#include "src/Support/TypeUtilities.hpp"
+
+using namespace mlir;
+
+namespace onnx_mlir {
+
+namespace {
+
+struct ONNXPadV13OpLoweringToMhlo : public ConversionPattern {
+  ONNXPadV13OpLoweringToMhlo(MLIRContext *ctx)
+      : ConversionPattern(mlir::ONNXPadV13Op::getOperationName(), 1, ctx) {}
+
+  LogicalResult matchAndRewrite(Operation *op, ArrayRef<Value> operands,
+      ConversionPatternRewriter &rewriter) const final {
+
+    Location loc = op->getLoc();
+    ONNXPadV13OpAdaptor operandAdaptor(operands, op->getAttrDictionary());
+    Value data = operandAdaptor.getData();
+    Value constantValue = operandAdaptor.getConstantValue();
+    Value pads = operandAdaptor.getPads();
+    StringRef padMode = operandAdaptor.getMode();
+
+    if (!padMode.equals_insensitive("constant"))
+        return failure();
+    assert(isRankedShapedType(data.getType()) && "Expected Ranked ShapedType");
+    ShapedType inputType = data.getType().cast<ShapedType>();
+    Type elemType = inputType.getElementType();
+    int64_t rank = inputType.getRank();
+
+    Type outputType = *op->result_type_begin();
+    if (!constantValue || isNoneValue(constantValue)) {
+      // Pad with zeros by default
+      constantValue = rewriter.create<mhlo::ConstantOp>(
+          loc, DenseElementsAttr::get(mlir::RankedTensorType::get({}, elemType),
+              rewriter.getZeroAttr(elemType)));
+    } else {
+      // constantValue might be 1D tensor, reshape it to scalar
+      constantValue = rewriter.create<mhlo::ReshapeOp>(
+        loc, RankedTensorType::get({}, elemType), constantValue);
+    }
+    SmallVector<int64_t> edgePaddingLowVec(rank, 0);
+    SmallVector<int64_t> edgePaddingHighVec(rank, 0);
+    SmallVector<int64_t> interiorPaddingVec(rank, 0);
+    if (auto valueAttribute = getElementAttributeFromMhloValue(pads)) {
+      // If `pads` are constants, read them."
+      int64_t idx = 0;
+      for (IntegerAttr value : valueAttribute.getValues<IntegerAttr>()) {
+        int64_t padValue = value.getInt();
+        if (padValue < 0)
+          return failure();
+        if (idx < rank)
+          edgePaddingLowVec[idx] = padValue;
+        else
+          edgePaddingHighVec[idx - rank] = padValue;
+        idx++;
+      }
+    } else {
+      assert(false && "Pads must be known at compile time");
+    }
+    
+    mlir::DenseIntElementsAttr edgePaddingLow =
+        rewriter.getI64VectorAttr(edgePaddingLowVec);
+    mlir::DenseIntElementsAttr edgePaddingHigh =
+        rewriter.getI64VectorAttr(edgePaddingHighVec);
+    mlir::DenseIntElementsAttr interiorPadding =
+        rewriter.getI64VectorAttr(interiorPaddingVec);
+    Value padResult = rewriter.create<mhlo::PadOp>(loc, outputType, data,
+        constantValue, edgePaddingLow, edgePaddingHigh, interiorPadding);
+
+    rewriter.replaceOp(op, padResult);
+    return success();
+  }
+};
+
+} // namespace
+
+void populateLoweringONNXPadOpToMhloPattern(
+    RewritePatternSet &patterns, MLIRContext *ctx) {
+  patterns.insert<ONNXPadV13OpLoweringToMhlo>(ctx);
+}
+
+} // namespace onnx_mlir
diff --git a/src/Dialect/ONNX/ONNXOps/ShapeHelper.hpp b/src/Dialect/ONNX/ONNXOps/ShapeHelper.hpp
index b5aa52f5..bbe5fd28 100644
--- a/src/Dialect/ONNX/ONNXOps/ShapeHelper.hpp
+++ b/src/Dialect/ONNX/ONNXOps/ShapeHelper.hpp
@@ -463,6 +463,16 @@ struct ONNXPadOpShapeHelper : public ONNXOpShapeHelper {
   llvm::SmallVector<IndexExpr, 4> pads;
 };
 
+struct ONNXPadV13OpShapeHelper : public ONNXOpShapeHelper {
+  ONNXPadV13OpShapeHelper(mlir::Operation *op, mlir::ValueRange operands,
+      IndexExprBuilder *ieBuilder = nullptr, IndexExprScope *scope = nullptr)
+      : ONNXOpShapeHelper(op, operands, ieBuilder, scope), pads() {}
+  virtual ~ONNXPadV13OpShapeHelper() {}
+  mlir::LogicalResult computeShape() final;
+  // Additional data for PadOp.
+  llvm::SmallVector<IndexExpr, 4> pads;
+};
+
 //===----------------------------------------------------------------------===//
 // OneHot Op
 //===----------------------------------------------------------------------===//
diff --git a/src/Dialect/ONNX/ONNXOps/Tensor/Pad.cpp b/src/Dialect/ONNX/ONNXOps/Tensor/Pad.cpp
index b00edc4a..f33bc18a 100644
--- a/src/Dialect/ONNX/ONNXOps/Tensor/Pad.cpp
+++ b/src/Dialect/ONNX/ONNXOps/Tensor/Pad.cpp
@@ -67,6 +67,49 @@ LogicalResult ONNXPadOpShapeHelper::computeShape() {
   return success();
 }
 
+LogicalResult ONNXPadV13OpShapeHelper::computeShape() {
+  ONNXPadOpAdaptor operandAdaptor(operands);
+  Value dataOperand = operandAdaptor.getData();
+  Value padsOperand = operandAdaptor.getPads();
+  DimsExpr outputDims;
+
+  // Get info about input data operand.
+  uint64_t dataRank = createIE->getShapedTypeRank(dataOperand);
+
+  // Initialize context and results (pads & output)
+  pads.resize(2 * dataRank); // pads two sides of each axis.
+  outputDims.resize(dataRank);
+
+  // `pads` format is : [x1_begin, x2_begin,...,x1_end, x2_end,...],
+  // where
+  // - xi_begin: the number of pad values added at the beginning of axis `i`
+  // - xi_end: the number of pad values added at the end of axis `i`.
+
+  // Calculate output dimension sizes.
+  for (uint64_t i = 0; i < dataRank; i++) {
+    // Get begin/end pads.
+    SymbolIndexExpr padBegin(createIE->getIntFromArrayAsSymbol(padsOperand, i));
+    SymbolIndexExpr padEnd(
+        createIE->getIntFromArrayAsSymbol(padsOperand, i + dataRank));
+    if (padBegin.isUndefined() || padEnd.isUndefined())
+      return op->emitError("pad parameter could not be processed");
+    // Get input dim.
+    DimIndexExpr dimInput(createIE->getShapeAsDim(dataOperand, i));
+
+    // Calculation for output size.
+    IndexExpr dimOutputFinal = (padBegin + dimInput) + padEnd;
+
+    // Save results.
+    pads[i] = padBegin;
+    pads[i + dataRank] = padEnd;
+    outputDims[i] = dimOutputFinal;
+  }
+
+  // Save the final result.
+  setOutputDims(outputDims);
+  return success();
+}
+
 } // namespace onnx_mlir
 
 //===----------------------------------------------------------------------===//
@@ -108,3 +151,15 @@ LogicalResult ONNXPadOp::inferShapes(
   ONNXPadOpShapeHelper shapeHelper(getOperation(), {});
   return shapeHelper.computeShapeAndUpdateType(elementType);
 }
+
+LogicalResult ONNXPadV13Op::inferShapes(
+    std::function<void(Region &)> doShapeInference) {
+  // Cannot infer shape if no shape exists.
+  if (!hasShapeAndRank(getData()) || !hasShapeAndRank(getPads()))
+    return success();
+
+  Type elementType = getData().getType().cast<ShapedType>().getElementType();
+
+  ONNXPadV13OpShapeHelper shapeHelper(getOperation(), {});
+  return shapeHelper.computeShapeAndUpdateType(elementType);
+}
diff --git a/src/Dialect/ONNX/ONNXUnsupportedOps.hpp b/src/Dialect/ONNX/ONNXUnsupportedOps.hpp
index 1ca21570..d431f29d 100644
--- a/src/Dialect/ONNX/ONNXUnsupportedOps.hpp
+++ b/src/Dialect/ONNX/ONNXUnsupportedOps.hpp
@@ -55,7 +55,6 @@ UNSUPPORTED_OPS(ONNXMomentumOp)
 UNSUPPORTED_OPS(ONNXMultinomialOp)
 UNSUPPORTED_OPS(ONNXNegativeLogLikelihoodLossOp)
 UNSUPPORTED_OPS(ONNXNormalizerOp)
-UNSUPPORTED_OPS(ONNXPadV13Op)
 UNSUPPORTED_OPS(ONNXPadV11Op)
 UNSUPPORTED_OPS(ONNXPadV2Op)
 UNSUPPORTED_OPS(ONNXRandomUniformLikeOp)
